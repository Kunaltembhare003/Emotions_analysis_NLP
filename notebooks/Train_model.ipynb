{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import sys\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.layers import GRU, Dense, Embedding, Flatten, Dropout\n",
    "from keras.activations import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer configuration and vocabulary from JSON file\n",
    "with open('D:\\project\\AWS\\Emotional_analysis_NLP\\data\\interim\\\\tokenizer.json', 'r') as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "tokenizer = tokenizer_from_json(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive blabbed enough tonight im tired ive feelin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woke really early morning drove feel ecstatic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel never gave rest day megabrick feeling stu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling restless teary flat sad strange today</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel like im doomed ive even began</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ive blabbed enough tonight im tired ive feelin...      0\n",
       "1  woke really early morning drove feel ecstatic ...      1\n",
       "2  feel never gave rest day megabrick feeling stu...      3\n",
       "3      feeling restless teary flat sad strange today      4\n",
       "4                 feel like im doomed ive even began      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data split into feature and target\n",
    "train = pd.read_csv('D:\\project\\AWS\\Emotional_analysis_NLP\\data\\processed\\\\train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text'].astype(str)\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id say maybe made feel foolish would reeeeeeal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joined lds church admit feeling somewhat asham...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>must admit didnt feel like hugging angry disgu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate still feel nerve damaged badly enough oft...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im actually feeling little smug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  id say maybe made feel foolish would reeeeeeal...      0\n",
       "1  joined lds church admit feeling somewhat asham...      0\n",
       "2  must admit didnt feel like hugging angry disgu...      3\n",
       "3  hate still feel nerve damaged badly enough oft...      0\n",
       "4                    im actually feeling little smug      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:\\project\\AWS\\Emotional_analysis_NLP\\data\\processed\\\\test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['text'].astype(str)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (333447,)\n",
      "X_test shape: (83362,)\n",
      "y_train shape: (333447,)\n",
      "y_test shape: (83362,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length (maxlen): 79\n"
     ]
    }
   ],
   "source": [
    "# Max Len in X_train_sequences\n",
    "maxlen = max(len(tokens) for tokens in X_train_sequences)\n",
    "print(\"Maximum sequence length (maxlen):\", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform padding on X_train and X_test sequences\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=maxlen, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  123,    33,   172, ...,     0,     0,     0],\n",
       "       [ 2941, 12893,   748, ...,     0,     0,     0],\n",
       "       [  194,   310,    48, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  851,   276,  1128, ...,     0,     0,     0],\n",
       "       [ 1874,  6225,   645, ...,     0,     0,     0],\n",
       "       [   83,     1,   401, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_padded:\n",
      "[[   20 26719    73 ...     0     0     0]\n",
      " [  275     5   738 ...     0     0     0]\n",
      " [    1    45   735 ...     0     0     0]\n",
      " ...\n",
      " [    1   606     0 ...     0     0     0]\n",
      " [    4    18   476 ...     0     0     0]\n",
      " [    1   149  1686 ...     0     0     0]]\n",
      "\n",
      "X_test_padded:\n",
      "[[  123    33   172 ...     0     0     0]\n",
      " [ 2941 12893   748 ...     0     0     0]\n",
      " [  194   310    48 ...     0     0     0]\n",
      " ...\n",
      " [  851   276  1128 ...     0     0     0]\n",
      " [ 1874  6225   645 ...     0     0     0]\n",
      " [   83     1   401 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the padded sequences for X_train and X_test\n",
    "print(\"X_train_padded:\")\n",
    "print(X_train_padded)\n",
    "print(\"\\nX_test_padded:\")\n",
    "print(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (333447, 79)\n",
      "X_test shape: (83362, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train_padded.shape}')\n",
    "print(f'X_test shape: {X_test_padded.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49510"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding Vocabulary Size \n",
    "vocabulary_size = len(set(token for sequence in X_train_padded for token in sequence))\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "- Sequential: This initializes a sequential model, allowing you to build the model layer by layer in a linear fashion.¶\n",
    "- Embedding layer: This layer is responsible for converting integer-encoded words into dense vectors of fixed size. It takes three parameters: input_dim, which specifies the size of the vocabulary (in this case, vocabulary_size), output_dim, which determines the dimension of the dense embedding, and input_length, which specifies the length of input sequences (in this case, maxlen).\n",
    "- Bidirectional GRU layer: This layer adds a bidirectional Gated Recurrent Unit (GRU) layer with 128 units. GRU is a type of recurrent neural network (RNN) that is similar to LSTM but has fewer parameters. The bidirectional wrapper allows the GRU to process input sequences in both forward and backward directions, enhancing the model's ability to capture long-range dependencies in the data.\n",
    "- Batch normalization layer: Batch normalization is a technique used to improve the training speed and stability of neural networks by normalizing the activations of each layer. It helps mitigate the internal covariate shift problem.\n",
    "- Dropout regularization: Dropout is a regularization technique that randomly sets a fraction of input units to zero during training, which helps prevent overfitting by reducing the reliance on specific neurons.\n",
    "- Dense layer with ReLU activation: This layer adds a fully connected dense layer with 64 units and Rectified Linear Unit (ReLU) activation function. ReLU is a non-linear activation function that introduces non-linearity to the model, allowing it to learn complex patterns in the data.\n",
    "- Dropout regularization: Another dropout layer is added after the dense layer to further prevent overfitting.\n",
    "- Output layer with softmax activation: The final layer is a dense layer with 6 units (assuming there are 6 classes) and softmax activation function. Softmax activation normalizes the output vector into a probability distribution over the classes, making it suitable for multi-class classification problems.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 75, 100)           6763500   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               176640    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6958002 (26.54 MB)\n",
      "Trainable params: 6957490 (26.54 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an embedding layer with input_dim=1000, output_dim=100, input_length=75\n",
    "model.add(Embedding(input_dim=vocabulary_size, output_dim=100,input_shape=(79,)))\n",
    "\n",
    "# Add a bidirectional GRU layer with 128 units\n",
    "model.add(Bidirectional(GRU(128)))\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add dropout regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add a dense layer with 64 units and ReLU activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add dropout regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer with 6 units for 6 labels and softmax activation\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 75), found shape=(None, 79)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Model Train \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6g08sh7s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 75), found shape=(None, 79)\n"
     ]
    }
   ],
   "source": [
    "# Model Train \n",
    "history = model.fit(X_train_padded, y_train,\n",
    "                     epochs=1, batch_size=1500,\n",
    "                       validation_data=(X_test_padded, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 75], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:868\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\input_layer.py:153\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;129;01mand\u001b[39;00m ragged:\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/project/AWS/Emotional_analysis_NLP/models/model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# Load the pre-trained sentiment analysis model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m         )\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    278\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:246\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 246\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:728\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m--> 728\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\sequential.py:466\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_config \u001b[38;5;129;01min\u001b[39;00m layer_configs:\n\u001b[0;32m    465\u001b[0m     use_legacy_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_config\n\u001b[1;32m--> 466\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_legacy_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(layer)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39minputs\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[0;32m    477\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\layers\\serialization.py:276\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_legacy_format:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m    270\u001b[0m         config,\n\u001b[0;32m    271\u001b[0m         module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[0;32m    272\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    273\u001b[0m         printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    274\u001b[0m     )\n\u001b[1;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:609\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[0;32m    603\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    604\u001b[0m                 serialize_with_public_fn(\n\u001b[0;32m    605\u001b[0m                     module_objects[config], config, fn_module_name\n\u001b[0;32m    606\u001b[0m                 ),\n\u001b[0;32m    607\u001b[0m                 custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    608\u001b[0m             )\n\u001b[1;32m--> 609\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserialize_with_public_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_config\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:728\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m--> 728\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[1;32mc:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 75], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('D:/project/AWS/Emotional_analysis_NLP/models/model.keras')# Load the pre-trained sentiment analysis model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kunal\\anaconda3\\envs\\Emo\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
