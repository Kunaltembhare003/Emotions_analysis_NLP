{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive blabbed enough tonight im tired ive feelin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woke really early morning drove feel ecstatic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel never gave rest day megabrick feeling stu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling restless teary flat sad strange today</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel like im doomed ive even began</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ive blabbed enough tonight im tired ive feelin...      0\n",
       "1  woke really early morning drove feel ecstatic ...      1\n",
       "2  feel never gave rest day megabrick feeling stu...      3\n",
       "3      feeling restless teary flat sad strange today      4\n",
       "4                 feel like im doomed ive even began      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data split into feature and target\n",
    "train = pd.read_csv('D:\\project\\AWS\\Emotional_analysis_NLP\\data\\processed\\\\train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text'].astype(str)\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id say maybe made feel foolish would reeeeeeal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joined lds church admit feeling somewhat asham...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>must admit didnt feel like hugging angry disgu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate still feel nerve damaged badly enough oft...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im actually feeling little smug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  id say maybe made feel foolish would reeeeeeal...      0\n",
       "1  joined lds church admit feeling somewhat asham...      0\n",
       "2  must admit didnt feel like hugging angry disgu...      3\n",
       "3  hate still feel nerve damaged badly enough oft...      0\n",
       "4                    im actually feeling little smug      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:\\project\\AWS\\Emotional_analysis_NLP\\data\\processed\\\\test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['text'].astype(str)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (333447,)\n",
      "X_test shape: (83362,)\n",
      "y_train shape: (333447,)\n",
      "y_test shape: (83362,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ive blabbed enough tonight im tired ive feelin...\n",
       "1         woke really early morning drove feel ecstatic ...\n",
       "2         feel never gave rest day megabrick feeling stu...\n",
       "3             feeling restless teary flat sad strange today\n",
       "4                        feel like im doomed ive even began\n",
       "                                ...                        \n",
       "333442                               feel love fell beloved\n",
       "333443    realized often time isnt reaction started feel...\n",
       "333444                                         feel envious\n",
       "333445    im still impatient frequently irritable time i...\n",
       "333446                                 feel weird apartment\n",
       "Name: text, Length: 333447, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and padding seq\n",
    "\n",
    "1. Tokenization: The text data in X_train and X_test is tokenized using the Tokenizer class from Keras. This step converts the text data into sequences of integers, where each unique word in the dataset is assigned a unique integer index. The num_words parameter limits the vocabulary size to 50,000 most frequent words.\n",
    "1. Padding: After tokenization, the sequences in X_train and X_test are padded to ensure uniform length. This is achieved using the pad_sequences function, which pads sequences with zeros to make them all of the same length (maxlen). Padding is done after the sequences to ensure that the actual content of the text is preserved.\n",
    "Overall, the code prepares the text data for further processing and modeling by converting it into tokenized and padded sequences, making it suitable for use in machine learning algorithms such as neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=50000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416809"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length (maxlen): 79\n"
     ]
    }
   ],
   "source": [
    "# Max Len in X_train_sequences\n",
    "maxlen = max(len(tokens) for tokens in X_train_sequences)\n",
    "print(\"Maximum sequence length (maxlen):\", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform padding on X_train and X_test sequences\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=maxlen, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_padded:\n",
      "[[   20 26719    73 ...     0     0     0]\n",
      " [  275     5   738 ...     0     0     0]\n",
      " [    1    45   735 ...     0     0     0]\n",
      " ...\n",
      " [    1   606     0 ...     0     0     0]\n",
      " [    4    18   476 ...     0     0     0]\n",
      " [    1   149  1686 ...     0     0     0]]\n",
      "\n",
      "X_test_padded:\n",
      "[[  123    33   172 ...     0     0     0]\n",
      " [ 2941 12893   748 ...     0     0     0]\n",
      " [  194   310    48 ...     0     0     0]\n",
      " ...\n",
      " [  851   276  1128 ...     0     0     0]\n",
      " [ 1874  6225   645 ...     0     0     0]\n",
      " [   83     1   401 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the padded sequences for X_train and X_test\n",
    "print(\"X_train_padded:\")\n",
    "print(X_train_padded)\n",
    "print(\"\\nX_test_padded:\")\n",
    "print(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (333447, 79)\n",
      "X_test shape: (83362, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train_padded.shape}')\n",
    "print(f'X_test shape: {X_test_padded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67634"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocalbulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49510"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding Vocabulary Size \n",
    "vocabulary_size = len(set(token for sequence in X_train_padded for token in sequence))\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
